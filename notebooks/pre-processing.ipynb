{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to pre-process the metadata downloaded from the database of interventions in congreso.es after being concatenated by legislature. Adds a new feature called \"political group\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir = 'data/interventions/merged-by-legislature'\n",
    "title = 'all-interventions-clean.csv'\n",
    "os.chdir(f'./{workdir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ct/921g5yd903j7f8wh5k85dltr0000gn/T/ipykernel_70550/3869542844.py:7: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  files.append(pd.read_csv(filenames[i]))\n",
      "/var/folders/ct/921g5yd903j7f8wh5k85dltr0000gn/T/ipykernel_70550/3869542844.py:7: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  files.append(pd.read_csv(filenames[i]))\n",
      "/var/folders/ct/921g5yd903j7f8wh5k85dltr0000gn/T/ipykernel_70550/3869542844.py:43: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data['enlace_pdf'] = data['enlace_pdf'].str.replace(r'\\#page=[\\d]{1,3}', '')\n"
     ]
    }
   ],
   "source": [
    "# Get all the file names.\n",
    "filenames = [i for i in glob.glob('*.csv')]\n",
    "\n",
    "files = []\n",
    "\n",
    "for i in range(0, len(filenames)):\n",
    "    files.append(pd.read_csv(filenames[i]))\n",
    "\n",
    "# Concatenate all files in one.\n",
    "data = pd.concat(files)\n",
    "\n",
    "# Keep only useful fields.\n",
    "data = data[['legislatura', 'fecha', 'objeto_iniciativa',\n",
    "    'numero_expediente', 'autores', 'nombre_sesion',\n",
    "    'orador', 'enlace_pdf']]\n",
    "\n",
    "# Eliminate around 15 rows in L03 that are missplaced.\n",
    "l = ['NUÑEZ ENCABO, MANUEL (GS)', 'MOYA PUEYO, VICENTE',\n",
    "    'PEREZ RUBALCABA, ALFREDO', 'TOCINO BISCAROLASAGA, ISABEL (GCP)',\n",
    "    'OLLERO TASSARA, ANDRES (APDP)',\n",
    "    'MONTESINOS GARCIA, JUAN ANTONIO (GCP)',\n",
    "    'CUENCA I VALERO, MARIA EUGENIA (GMC)',\n",
    "    'GARCIA FONSECA, MANUEL (AIU-EC)', 'VILLAMOR LEON, JOSE']\n",
    "\n",
    "data = data.drop(data.loc[data['fecha'].isin(l)].index)\n",
    "\n",
    "# Eliminate 4 rows of data with errors.\n",
    "l2 = ['COMPARECENCIA DE AUTORIDADES Y FUNCIONARIOS EN COMISION.',\n",
    "      'COMPARECENCIA DEL GOBIERNO EN COMISION (ART. 44).']\n",
    "\n",
    "data = data.drop(data.loc[data['legislatura'].isin(l2)].index)\n",
    "\n",
    "# Eliminating 2 rows in L06 that are missplaced.\n",
    "data = data.loc[(data['fecha'] != 'Pregunta-Contestación')]\n",
    "\n",
    "# Fecha to datetime format.\n",
    "data['fecha'] = pd.to_datetime(data['fecha'], format='%d/%m/%Y')\n",
    "\n",
    "# Removing the  page reference since it is not needed and does not allow to drop duplicates.\n",
    "data = data.astype({'enlace_pdf':'string'})\n",
    "\n",
    "# ERROR here. The digit itself is not being replaced.\n",
    "data['enlace_pdf'] = data['enlace_pdf'].str.replace(r'\\#page=[\\d]{1,3}', '')\n",
    "\n",
    "# Remove duplicates.\n",
    "data = data.sort_values(by=['fecha', 'enlace_pdf']).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Eliminate NaNs.\n",
    "data = data.dropna()\n",
    "\n",
    "# Eliminate rows if they correspond to constitution of commissions because these are irrelevant.\n",
    "data = data[data['objeto_iniciativa'].str.contains('Constitución de la Comisión') == False]\n",
    "\n",
    "# Reset index.\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "# Substitute roman numbers for integers values.\n",
    "data['legislatura'] = data['legislatura'].replace({'I': 1, 'II': 2, 'III': 3, 'IV': 4, 'V': 5, 'VI': 6, 'VII': 7, 'VIII': 8, 'IX': 9, 'X': 10, 'XI': 11, 'XII': 12, 'XIII': 13, 'XIV': 14})\n",
    "\n",
    "# Adding the political group as a new feature.\n",
    "political_group = data['orador'].str.split(r' \\(', 1)\n",
    "\n",
    "# Filling the cases where there is no political group.\n",
    "for i in range(len(political_group)):\n",
    "    try: political_group[i][1]\n",
    "    except: political_group[i].append('')\n",
    "\n",
    "# Clean the list to only include the political group, e.g. GP, GCUP-EC-GC, GS.\n",
    "political_group = [political_group[i][1][:-1]\n",
    "                   for i in range(len(political_group))]\n",
    "\n",
    "# Add the column in the DF.\n",
    "data['political_group'] = political_group\n",
    "\n",
    "# Save new file.\n",
    "data.to_csv(f'../{title}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we can only obtain the texts for legislatures 6 until 14, I splitted this data into another .csv file.\n",
    "vi_to_xiv = data.loc[data['legislatura'] > 5].reset_index(drop=True)\n",
    "vi_to_xiv.to_csv(f'../vi-xiv-clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining a file per legislature.\n",
    "vi   = data.loc[data['legislatura'] ==  6].reset_index(drop=True)\n",
    "vii  = data.loc[data['legislatura'] ==  7].reset_index(drop=True)\n",
    "viii = data.loc[data['legislatura'] ==  8].reset_index(drop=True)\n",
    "ix   = data.loc[data['legislatura'] ==  9].reset_index(drop=True)\n",
    "x    = data.loc[data['legislatura'] == 10].reset_index(drop=True)\n",
    "xi   = data.loc[data['legislatura'] == 11].reset_index(drop=True)\n",
    "xii  = data.loc[data['legislatura'] == 12].reset_index(drop=True)\n",
    "xiii = data.loc[data['legislatura'] == 13].reset_index(drop=True)\n",
    "xiv  = data.loc[data['legislatura'] == 14].reset_index(drop=True)\n",
    "\n",
    "vi.to_csv(f'../L06-clean.csv', index=False)\n",
    "vii.to_csv(f'../L07-clean.csv', index=False)\n",
    "viii.to_csv(f'../L08-clean.csv', index=False)\n",
    "ix.to_csv(f'../L09-clean.csv', index=False)\n",
    "x.to_csv(f'../L10-clean.csv', index=False)\n",
    "xi.to_csv(f'../L11-clean.csv', index=False)\n",
    "xii.to_csv(f'../L12-clean.csv', index=False)\n",
    "xiii.to_csv(f'../L13-clean.csv', index=False)\n",
    "xiv.to_csv(f'../L14-clean.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d5936845f3ebb1b8d781f4d1c64232f5e580c1c1d69bfd2287ad8814f75b67c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
